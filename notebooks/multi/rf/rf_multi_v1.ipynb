{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 1: Import Libraries and Setup Paths\n",
    "import cudf\n",
    "import cupy as cp\n",
    "from cuml import RandomForestClassifier\n",
    "from cuml.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from cuml.metrics.confusion_matrix import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Define paths\n",
    "processed_train_path = '/root/autodl-tmp/projects/SL_NSL/dataset/processed/multi/KDDTrain_processed.csv'\n",
    "processed_test_path = '/root/autodl-tmp/projects/SL_NSL/dataset/processed/multi/KDDTest_processed.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading processed training data...\n",
      "\n",
      "Checking for missing values in training data:\n",
      "dst_host_srv_count    0\n",
      "logged_in             0\n",
      "flag_SF               0\n",
      "service_http          0\n",
      "service_private       0\n",
      "                     ..\n",
      "urgent                0\n",
      "land                  0\n",
      "is_host_login         0\n",
      "service_tim_i         0\n",
      "multiclass_label      0\n",
      "Length: 110, dtype: int64\n",
      "\n",
      "Feature matrix shape: (125973, 109)\n",
      "Label distribution:\n",
      "0    67343\n",
      "1    45927\n",
      "2    11656\n",
      "3      995\n",
      "4       52\n",
      "Name: multiclass_label, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Cell 2: Load training data\n",
    "print(\"Loading processed training data...\")\n",
    "df_train = cudf.read_csv(processed_train_path)\n",
    "\n",
    "# Handle missing values in training data\n",
    "print(\"\\nChecking for missing values in training data:\")\n",
    "print(df_train.isnull().sum().to_pandas())\n",
    "\n",
    "# Fill missing values if any exist\n",
    "df_train = df_train.fillna(df_train.mean())\n",
    "\n",
    "# Select features and labels\n",
    "X = df_train.drop(columns=['multiclass_label']).astype('float32')\n",
    "y_multi = df_train['multiclass_label']\n",
    "\n",
    "# Display data info\n",
    "print(\"\\nFeature matrix shape:\", X.shape)\n",
    "print(\"Label distribution:\")\n",
    "print(y_multi.value_counts().to_pandas())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset split complete\n",
      "Training samples: 100778\n",
      "Validation samples: 25195\n"
     ]
    }
   ],
   "source": [
    "# Cell 3: Split into training and validation sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y_multi, test_size=0.2, random_state=42,\n",
    ")\n",
    "\n",
    "# Data type conversion\n",
    "X_train = X_train.astype('float32')\n",
    "X_test = X_test.astype('float32')\n",
    "\n",
    "print(\"Dataset split complete\")\n",
    "print(f\"Training samples: {X_train.shape[0]}\")\n",
    "print(f\"Validation samples: {X_test.shape[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training Random Forest model on GPU...\n",
      "\n",
      "Evaluating on validation set...\n",
      "Validation Accuracy: 1.00\n",
      "\n",
      "Confusion Matrix:\n",
      "[[13413     4     5     0     0]\n",
      " [   10  9171     0     0     0]\n",
      " [   32     2  2323     0     0]\n",
      " [   26     0     0   198     0]\n",
      " [   10     0     0     0     1]]\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      1.00     13422\n",
      "           1       1.00      1.00      1.00      9181\n",
      "           2       1.00      0.99      0.99      2357\n",
      "           3       1.00      0.88      0.94       224\n",
      "           4       1.00      0.09      0.17        11\n",
      "\n",
      "    accuracy                           1.00     25195\n",
      "   macro avg       1.00      0.79      0.82     25195\n",
      "weighted avg       1.00      1.00      1.00     25195\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Cell 4: Create and train Random Forest model\n",
    "print(\"\\nTraining Random Forest model on GPU...\")\n",
    "rf_multi = RandomForestClassifier(n_estimators=100, random_state=42, n_streams=1)\n",
    "rf_multi.fit(X_train, y_train)\n",
    "\n",
    "# Predict and evaluate on validation set\n",
    "print(\"\\nEvaluating on validation set...\")\n",
    "y_pred = rf_multi.predict(X_test)\n",
    "\n",
    "# Data type conversion\n",
    "y_pred = y_pred.astype('int32')\n",
    "y_test = y_test.astype('int32')\n",
    "\n",
    "# Calculate metrics\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "# Convert to CPU for classification report\n",
    "y_test_cpu = y_test.to_pandas()\n",
    "y_pred_cpu = y_pred.to_pandas()\n",
    "class_report = classification_report(y_test_cpu, y_pred_cpu)\n",
    "\n",
    "print(f\"Validation Accuracy: {accuracy:.2f}\")\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "print(conf_matrix)\n",
    "print(\"\\nClassification Report:\")\n",
    "print(class_report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluating on validation set...\n",
      "Validation Accuracy: 1.00\n",
      "\n",
      "Confusion Matrix:\n",
      "[[13413     4     5     0     0]\n",
      " [   10  9171     0     0     0]\n",
      " [   32     2  2323     0     0]\n",
      " [   26     0     0   198     0]\n",
      " [   10     0     0     0     1]]\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      1.00     13422\n",
      "           1       1.00      1.00      1.00      9181\n",
      "           2       1.00      0.99      0.99      2357\n",
      "           3       1.00      0.88      0.94       224\n",
      "           4       1.00      0.09      0.17        11\n",
      "\n",
      "    accuracy                           1.00     25195\n",
      "   macro avg       1.00      0.79      0.82     25195\n",
      "weighted avg       1.00      1.00      1.00     25195\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Cell 5: Predict and evaluate on validation set again\n",
    "print(\"\\nEvaluating on validation set...\")\n",
    "\n",
    "# Ensure data types\n",
    "y_test = y_test.astype('int32')\n",
    "\n",
    "# Make predictions and convert to int32\n",
    "y_pred = rf_multi.predict(X_test)\n",
    "y_pred = cudf.Series(y_pred).astype('int32')\n",
    "\n",
    "# Calculate metrics\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "# Convert to CPU for classification report\n",
    "y_test_cpu = y_test.to_pandas()\n",
    "y_pred_cpu = y_pred.to_pandas()\n",
    "class_report = classification_report(y_test_cpu, y_pred_cpu)\n",
    "\n",
    "print(f\"Validation Accuracy: {accuracy:.2f}\")\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "print(conf_matrix)\n",
    "print(\"\\nClassification Report:\")\n",
    "print(class_report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluating on external test set...\n",
      "\n",
      "Checking for missing values in test data:\n",
      "dst_host_srv_count       0\n",
      "logged_in                0\n",
      "flag_SF                  0\n",
      "service_http             0\n",
      "service_private          0\n",
      "                      ... \n",
      "urgent                   0\n",
      "land                     0\n",
      "is_host_login            0\n",
      "service_tim_i            0\n",
      "multiclass_label      2420\n",
      "Length: 110, dtype: int64\n",
      "\n",
      "Verifying no missing values in predictions and labels:\n",
      "Missing in predictions: 0\n",
      "Missing in actual labels: 0\n",
      "\n",
      "External Test Set Accuracy: 0.73\n",
      "\n",
      "Confusion Matrix:\n",
      "[[9631 2050  450    0    0]\n",
      " [ 354 5387    0    0    0]\n",
      " [ 390  639 1392    0    0]\n",
      " [1848  347    4    0    0]\n",
      " [  52    0    0    0    0]]\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.79      0.79     12131\n",
      "           1       0.64      0.94      0.76      5741\n",
      "           2       0.75      0.57      0.65      2421\n",
      "           3       0.00      0.00      0.00      2199\n",
      "           4       0.00      0.00      0.00        52\n",
      "\n",
      "    accuracy                           0.73     22544\n",
      "   macro avg       0.44      0.46      0.44     22544\n",
      "weighted avg       0.67      0.73      0.69     22544\n",
      "\n",
      "\n",
      "Prediction distribution:\n",
      "0    12275\n",
      "1     8423\n",
      "2     1846\n",
      "dtype: int64\n",
      "\n",
      "True label distribution:\n",
      "0    12131\n",
      "1     5741\n",
      "2     2421\n",
      "3     2199\n",
      "4       52\n",
      "Name: multiclass_label, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Cell 6: Load and evaluate on external test set\n",
    "print(\"\\nEvaluating on external test set...\")\n",
    "df_test = cudf.read_csv(processed_test_path)\n",
    "\n",
    "# Check for missing values in test data\n",
    "print(\"\\nChecking for missing values in test data:\")\n",
    "print(df_test.isnull().sum().to_pandas())\n",
    "\n",
    "# Fill missing values in test data\n",
    "df_test = df_test.fillna(df_test.mean())\n",
    "\n",
    "X_external_test = df_test.drop(columns=['multiclass_label']).astype('float32')\n",
    "y_external_test = df_test['multiclass_label'].astype('int32')\n",
    "\n",
    "# Make predictions\n",
    "y_external_pred = rf_multi.predict(X_external_test)\n",
    "y_external_pred = cudf.Series(y_external_pred).astype('int32')\n",
    "\n",
    "# Verify no missing values\n",
    "print(\"\\nVerifying no missing values in predictions and labels:\")\n",
    "print(\"Missing in predictions:\", y_external_pred.isnull().sum())\n",
    "print(\"Missing in actual labels:\", y_external_test.isnull().sum())\n",
    "\n",
    "# Calculate metrics\n",
    "accuracy_external = accuracy_score(y_external_test, y_external_pred)\n",
    "conf_matrix_external = confusion_matrix(y_external_test, y_external_pred)\n",
    "\n",
    "# Convert to CPU for classification report\n",
    "y_external_test_cpu = y_external_test.to_pandas()\n",
    "y_external_pred_cpu = y_external_pred.to_pandas()\n",
    "class_report_external = classification_report(y_external_test_cpu, y_external_pred_cpu, zero_division=0)\n",
    "\n",
    "print(f\"\\nExternal Test Set Accuracy: {accuracy_external:.2f}\")\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "print(conf_matrix_external)\n",
    "print(\"\\nClassification Report:\")\n",
    "print(class_report_external)\n",
    "\n",
    "# Print the distribution of predicted labels\n",
    "print(\"\\nPrediction distribution:\")\n",
    "print(cudf.Series(y_external_pred).value_counts().sort_index().to_pandas())\n",
    "print(\"\\nTrue label distribution:\")\n",
    "print(cudf.Series(y_external_test).value_counts().sort_index().to_pandas())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sl-nsl-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

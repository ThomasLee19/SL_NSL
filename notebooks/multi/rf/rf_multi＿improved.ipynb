{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 1: Import Libraries and Setup Paths\n",
    "import cudf\n",
    "import cupy as cp\n",
    "import numpy as np\n",
    "from cuml.ensemble import RandomForestClassifier\n",
    "from cuml.metrics import accuracy_score\n",
    "from cuml.model_selection import train_test_split\n",
    "from cuml.metrics.confusion_matrix import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.metrics import make_scorer, f1_score\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Define paths\n",
    "processed_train_path = '/root/autodl-tmp/projects/SL_NSL/dataset/processed/multi/KDDTrain_processed.csv'\n",
    "processed_test_path = '/root/autodl-tmp/projects/SL_NSL/dataset/processed/multi/KDDTest_processed.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 2: Define Data Loading and Preprocessing Functions\n",
    "def load_and_preprocess_data(train_path, test_path, verbose=True):\n",
    "    \"\"\"\n",
    "    Load and preprocess both training and test data\n",
    "    \"\"\"\n",
    "    if verbose:\n",
    "        print(\"Loading and preprocessing data...\")\n",
    "    \n",
    "    # Load training data\n",
    "    df_train = cudf.read_csv(train_path)\n",
    "    df_test = cudf.read_csv(test_path)\n",
    "    \n",
    "    # Convert feature columns to float32\n",
    "    feature_cols = [col for col in df_train.columns if col != 'multiclass_label']\n",
    "    df_train[feature_cols] = df_train[feature_cols].astype('float32')\n",
    "    df_test[feature_cols] = df_test[feature_cols].astype('float32')\n",
    "    \n",
    "    # Handle missing values\n",
    "    df_train = df_train.fillna(df_train.mean())\n",
    "    df_test = df_test.fillna(df_test.mean())\n",
    "    \n",
    "    # Split features and labels\n",
    "    X_train = df_train[feature_cols]\n",
    "    y_train = df_train['multiclass_label'].astype('int32')\n",
    "    X_test = df_test[feature_cols]\n",
    "    y_test = df_test['multiclass_label'].astype('int32')\n",
    "    \n",
    "    if verbose:\n",
    "        print(\"Class distribution in training data:\")\n",
    "        print(y_train.value_counts().sort_index().to_pandas())\n",
    "    \n",
    "    return X_train, X_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 3: Define Improved Sampling Function\n",
    "def adaptive_sampling(X, y, verbose=False):\n",
    "    \"\"\"\n",
    "    Perform adaptive sampling with different ratios for each class\n",
    "    \"\"\"\n",
    "    X_cpu = X.to_pandas().values if isinstance(X, cudf.DataFrame) else X\n",
    "    y_cpu = y.to_pandas().values if isinstance(y, cudf.Series) else y\n",
    "    \n",
    "    # Calculate class distributions\n",
    "    class_counts = np.bincount(y_cpu)\n",
    "    if verbose:\n",
    "        print(\"Original class distribution:\")\n",
    "        print(class_counts)\n",
    "    \n",
    "    # Calculate sampling strategy - different ratios for different classes\n",
    "    sampling_strategy = {\n",
    "        1: int(class_counts[1] * 1.2), \n",
    "        2: int(class_counts[2] * 2.0),  \n",
    "        3: int(class_counts[3] * 5.0),  \n",
    "        4: int(class_counts[4] * 10.0)  \n",
    "    }\n",
    "    \n",
    "    # Apply SMOTE with adaptive strategy\n",
    "    smote = SMOTE(\n",
    "        sampling_strategy=sampling_strategy,\n",
    "        random_state=42,\n",
    "        k_neighbors=min(5, min(class_counts[class_counts > 0]) - 1)\n",
    "    )\n",
    "    \n",
    "    X_resampled, y_resampled = smote.fit_resample(X_cpu, y_cpu)\n",
    "    \n",
    "    if verbose:\n",
    "        print(\"\\nClass distribution after sampling:\")\n",
    "        print(np.bincount(y_resampled))\n",
    "    \n",
    "    return X_resampled, y_resampled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 4: Define Evaluation on Imbalanced Data Function\n",
    "def evaluate_on_imbalanced(model, X_val, y_val):\n",
    "    y_pred = model.predict(X_val)\n",
    "    # 使用macro平均而不是weighted\n",
    "    score = f1_score(\n",
    "        y_val.to_pandas(),\n",
    "        y_pred.to_pandas(),\n",
    "        average='macro'\n",
    "    )\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 5: Define Grid Search Function\n",
    "def perform_grid_search(X, y, base_model):\n",
    "    \"\"\"\n",
    "    Perform grid search with optimized parameter space\n",
    "    \"\"\"\n",
    "    print(\"\\nPerforming grid search...\")\n",
    "    \n",
    "    # Optimized parameter grid\n",
    "    param_grid = {\n",
    "        'n_estimators': [200, 300],\n",
    "        'max_depth': [20, 25, 30],\n",
    "        'min_samples_split': [10, 15],\n",
    "        'max_features': [0.7, 0.8, 0.9],\n",
    "        'min_samples_leaf': [5, 10]\n",
    "    }\n",
    "    \n",
    "    best_score = 0\n",
    "    best_params = {}\n",
    "    \n",
    "    # Convert data for grid search\n",
    "    X_cpu = X.to_pandas().values if isinstance(X, cudf.DataFrame) else X\n",
    "    y_cpu = y.to_pandas().values if isinstance(y, cudf.Series) else y\n",
    "    \n",
    "    # Create CV splits\n",
    "    cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "    \n",
    "    # Generate parameter combinations\n",
    "    param_combinations = [\n",
    "        {'n_estimators': n, 'max_depth': d, 'min_samples_split': s, \n",
    "         'max_features': f, 'min_samples_leaf': l}\n",
    "        for n in param_grid['n_estimators']\n",
    "        for d in param_grid['max_depth']\n",
    "        for s in param_grid['min_samples_split']\n",
    "        for f in param_grid['max_features']\n",
    "        for l in param_grid['min_samples_leaf']\n",
    "    ]\n",
    "    \n",
    "    # Progress bar for parameter combinations\n",
    "    for params in tqdm(param_combinations, desc=\"Parameter combinations\"):\n",
    "        model = RandomForestClassifier(**params, n_bins=256, n_streams=1, random_state=42)\n",
    "        scores = []\n",
    "        \n",
    "        # Progress bar for cross-validation\n",
    "        for train_idx, val_idx in cv.split(X_cpu, y_cpu):\n",
    "            X_train_fold = cudf.DataFrame(X_cpu[train_idx])\n",
    "            y_train_fold = cudf.Series(y_cpu[train_idx])\n",
    "            X_val_fold = cudf.DataFrame(X_cpu[val_idx])\n",
    "            y_val_fold = cudf.Series(y_cpu[val_idx])\n",
    "            \n",
    "            # Balance training data\n",
    "            X_train_balanced, y_train_balanced = adaptive_sampling(\n",
    "                X_train_fold, y_train_fold, verbose=False\n",
    "            )\n",
    "            X_train_balanced = cudf.DataFrame(X_train_balanced)\n",
    "            y_train_balanced = cudf.Series(y_train_balanced)\n",
    "            \n",
    "            # Train model\n",
    "            model.fit(X_train_balanced, y_train_balanced)\n",
    "            \n",
    "            # Evaluate on original distribution\n",
    "            score = evaluate_on_imbalanced(model, X_val_fold, y_val_fold)\n",
    "            scores.append(score)\n",
    "        \n",
    "        avg_score = np.mean(scores)\n",
    "        if avg_score > best_score:\n",
    "            best_score = avg_score\n",
    "            best_params = params\n",
    "            print(f\"\\nNew best score: {best_score:.3f} with params: {best_params}\")\n",
    "    \n",
    "    return best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 6: Define Model Evaluation Function\n",
    "def evaluate_model(model, X, y, dataset_name=\"\"):\n",
    "    \"\"\"\n",
    "    Evaluate model performance with multiple metrics\n",
    "    \"\"\"\n",
    "    print(f\"\\nEvaluating on {dataset_name}...\")\n",
    "    y_pred = model.predict(X)\n",
    "    \n",
    "    # Convert to correct types\n",
    "    y = y.astype('int32')\n",
    "    y_pred = cudf.Series(y_pred).astype('int32')\n",
    "    \n",
    "    # Calculate metrics\n",
    "    accuracy = accuracy_score(y, y_pred)\n",
    "    conf_mat = confusion_matrix(y, y_pred)\n",
    "    \n",
    "    # Calculate class-specific metrics\n",
    "    y_cpu = y.to_pandas()\n",
    "    y_pred_cpu = y_pred.to_pandas()\n",
    "    class_report = classification_report(y_cpu, y_pred_cpu)\n",
    "    \n",
    "    print(f\"Accuracy: {accuracy:.3f}\")\n",
    "    print(\"\\nConfusion Matrix:\")\n",
    "    print(conf_mat)\n",
    "    print(\"\\nClassification Report:\")\n",
    "    print(class_report)\n",
    "    \n",
    "    # Print prediction distribution\n",
    "    print(\"\\nPrediction distribution:\")\n",
    "    print(y_pred.value_counts().sort_index().to_pandas())\n",
    "    print(\"\\nTrue label distribution:\")\n",
    "    print(y.value_counts().sort_index().to_pandas())\n",
    "    \n",
    "    return {\n",
    "        'accuracy': accuracy,\n",
    "        'confusion_matrix': conf_mat,\n",
    "        'classification_report': class_report\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 7: Define Main Function\n",
    "def main():\n",
    "    # Load and preprocess data\n",
    "    print(\"Step 1/5: Loading and preprocessing data...\")\n",
    "    X_train, X_external, y_train, y_external = load_and_preprocess_data(\n",
    "        processed_train_path, processed_test_path\n",
    "    )\n",
    "    \n",
    "    # Split training data\n",
    "    print(\"\\nStep 2/5: Splitting training data...\")\n",
    "    X_train_split, X_val, y_train_split, y_val = train_test_split(\n",
    "        X_train, y_train, test_size=0.2, random_state=42\n",
    "    )\n",
    "    \n",
    "    # Create base model\n",
    "    print(\"\\nStep 3/5: Creating base model...\")\n",
    "    base_model = RandomForestClassifier(\n",
    "        n_estimators=200,\n",
    "        max_depth=25,\n",
    "        min_samples_leaf=10,\n",
    "        min_samples_split=15,\n",
    "        max_features=0.8,\n",
    "        n_bins=256,\n",
    "        n_streams=1,\n",
    "        random_state=42\n",
    "    )\n",
    "    \n",
    "    # Perform grid search\n",
    "    print(\"\\nStep 4/5: Performing grid search...\")\n",
    "    best_params = perform_grid_search(X_train_split, y_train_split, base_model)\n",
    "    \n",
    "    # Create and train final model\n",
    "    print(\"\\nStep 5/5: Training final model...\")\n",
    "    final_model = RandomForestClassifier(\n",
    "        **best_params,\n",
    "        n_bins=256,\n",
    "        n_streams=1,\n",
    "        random_state=42\n",
    "    )\n",
    "    \n",
    "    # Balance training data\n",
    "    print(\"\\nBalancing training data...\")\n",
    "    X_train_balanced, y_train_balanced = adaptive_sampling(X_train, y_train, verbose=True)\n",
    "    X_train_balanced = cudf.DataFrame(X_train_balanced)\n",
    "    y_train_balanced = cudf.Series(y_train_balanced)\n",
    "    \n",
    "    # Train final model\n",
    "    print(\"\\nTraining final model...\")\n",
    "    final_model.fit(X_train_balanced, y_train_balanced)\n",
    "    \n",
    "    # Evaluate model\n",
    "    val_metrics = evaluate_model(final_model, X_val, y_val, \"validation set\")\n",
    "    external_metrics = evaluate_model(final_model, X_external, y_external, \"external test set\")\n",
    "    \n",
    "    return final_model, val_metrics, external_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 1/5: Loading and preprocessing data...\n",
      "Loading and preprocessing data...\n",
      "Class distribution in training data:\n",
      "0    67343\n",
      "1    45927\n",
      "2    11656\n",
      "3      995\n",
      "4       52\n",
      "Name: multiclass_label, dtype: int64\n",
      "\n",
      "Step 2/5: Splitting training data...\n",
      "\n",
      "Step 3/5: Creating base model...\n",
      "\n",
      "Step 4/5: Performing grid search...\n",
      "\n",
      "Performing grid search...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parameter combinations:   1%|▏         | 1/72 [00:21<25:02, 21.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "New best score: 0.935 with params: {'n_estimators': 200, 'max_depth': 20, 'min_samples_split': 10, 'max_features': 0.7, 'min_samples_leaf': 5}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parameter combinations:  10%|▉         | 7/72 [02:32<23:48, 21.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "New best score: 0.936 with params: {'n_estimators': 200, 'max_depth': 20, 'min_samples_split': 15, 'max_features': 0.7, 'min_samples_leaf': 5}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parameter combinations:  51%|█████▏    | 37/72 [13:46<14:24, 24.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "New best score: 0.941 with params: {'n_estimators': 300, 'max_depth': 20, 'min_samples_split': 10, 'max_features': 0.7, 'min_samples_leaf': 5}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parameter combinations:  68%|██████▊   | 49/72 [19:57<11:51, 30.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "New best score: 0.941 with params: {'n_estimators': 300, 'max_depth': 25, 'min_samples_split': 10, 'max_features': 0.7, 'min_samples_leaf': 5}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parameter combinations: 100%|██████████| 72/72 [31:56<00:00, 26.61s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Step 5/5: Training final model...\n",
      "\n",
      "Balancing training data...\n",
      "Original class distribution:\n",
      "[67343 45927 11656   995    52]\n",
      "\n",
      "Class distribution after sampling:\n",
      "[67343 55112 23312  4975   520]\n",
      "\n",
      "Training final model...\n",
      "\n",
      "Evaluating on validation set...\n",
      "Accuracy: 1.000\n",
      "\n",
      "Confusion Matrix:\n",
      "[[13493     3     3     0     0]\n",
      " [    1  9120     0     0     0]\n",
      " [    2     0  2364     0     0]\n",
      " [    1     0     0   196     1]\n",
      " [    1     0     0     0     9]]\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     13499\n",
      "           1       1.00      1.00      1.00      9121\n",
      "           2       1.00      1.00      1.00      2366\n",
      "           3       1.00      0.99      0.99       198\n",
      "           4       0.90      0.90      0.90        10\n",
      "\n",
      "    accuracy                           1.00     25194\n",
      "   macro avg       0.98      0.98      0.98     25194\n",
      "weighted avg       1.00      1.00      1.00     25194\n",
      "\n",
      "\n",
      "Prediction distribution:\n",
      "0    13498\n",
      "1     9123\n",
      "2     2367\n",
      "3      196\n",
      "4       10\n",
      "dtype: int64\n",
      "\n",
      "True label distribution:\n",
      "0    13499\n",
      "1     9121\n",
      "2     2366\n",
      "3      198\n",
      "4       10\n",
      "Name: multiclass_label, dtype: int64\n",
      "\n",
      "Evaluating on external test set...\n",
      "Accuracy: 0.558\n",
      "\n",
      "Confusion Matrix:\n",
      "[[5660 5640  829    2    0]\n",
      " [   6 5701   34    0    0]\n",
      " [   2 1271 1148    0    0]\n",
      " [ 149 1828  143   79    0]\n",
      " [   5   40    5    2    0]]\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.47      0.63     12131\n",
      "           1       0.39      0.99      0.56      5741\n",
      "           2       0.53      0.47      0.50      2421\n",
      "           3       0.95      0.04      0.07      2199\n",
      "           4       0.00      0.00      0.00        52\n",
      "\n",
      "    accuracy                           0.56     22544\n",
      "   macro avg       0.57      0.39      0.35     22544\n",
      "weighted avg       0.77      0.56      0.54     22544\n",
      "\n",
      "\n",
      "Prediction distribution:\n",
      "0     5822\n",
      "1    14480\n",
      "2     2159\n",
      "3       83\n",
      "dtype: int64\n",
      "\n",
      "True label distribution:\n",
      "0    12131\n",
      "1     5741\n",
      "2     2421\n",
      "3     2199\n",
      "4       52\n",
      "Name: multiclass_label, dtype: int64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniconda3/envs/sl-nsl-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/root/miniconda3/envs/sl-nsl-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/root/miniconda3/envs/sl-nsl-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "# Cell 8: Execute Main Function\n",
    "if __name__ == \"__main__\":\n",
    "    final_model, val_metrics, external_metrics = main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sl-nsl-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

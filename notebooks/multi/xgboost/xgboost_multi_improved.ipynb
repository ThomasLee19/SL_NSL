{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 1: Import Libraries and Setup Paths\n",
    "import cudf\n",
    "import numpy as np\n",
    "from cuml.model_selection import train_test_split, StratifiedKFold\n",
    "from xgboost import XGBClassifier\n",
    "from cuml.metrics import accuracy_score, confusion_matrix\n",
    "from sklearn.metrics import classification_report, precision_recall_curve\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from imblearn.pipeline import make_pipeline\n",
    "from sklearn.feature_selection import SelectKBest, f_classif\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Define paths\n",
    "processed_train_path = '/root/autodl-tmp/projects/SL_NSL/dataset/processed/multi/KDDTrain_processed.csv'\n",
    "processed_test_path = '/root/autodl-tmp/projects/SL_NSL/dataset/processed/multi/KDDTest_processed.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 2: Load and Preprocess Training Data\n",
    "def load_and_preprocess_data(train_path, test_path, verbose=True):\n",
    "    if verbose:\n",
    "        print(\"Loading and preprocessing data...\")\n",
    "    \n",
    "    # Load training and test data\n",
    "    df_train = cudf.read_csv(train_path)\n",
    "    df_test = cudf.read_csv(test_path)\n",
    "    \n",
    "    # Convert feature columns to float32\n",
    "    feature_cols = [col for col in df_train.columns if col != 'multiclass_label']\n",
    "    df_train[feature_cols] = df_train[feature_cols].astype('float32')\n",
    "    df_test[feature_cols] = df_test[feature_cols].astype('float32')\n",
    "    \n",
    "    # Handle missing values\n",
    "    df_train = df_train.fillna(df_train.mean())\n",
    "    df_test = df_test.fillna(df_test.mean())\n",
    "    \n",
    "    # Split features and labels\n",
    "    X_train = df_train[feature_cols]\n",
    "    y_train = df_train['multiclass_label'].astype('int32')\n",
    "    X_test = df_test[feature_cols]\n",
    "    y_test = df_test['multiclass_label'].astype('int32')\n",
    "    \n",
    "    if verbose:\n",
    "        print(\"Class distribution in training data:\")\n",
    "        print(y_train.value_counts().sort_index().to_pandas())\n",
    "    \n",
    "    return X_train, X_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 3: Define Adaptive Sampling Function\n",
    "def adaptive_sampling(X, y, verbose=False):\n",
    "    X_cpu = X.to_pandas().values if isinstance(X, cudf.DataFrame) else X\n",
    "    y_cpu = y.to_pandas().values if isinstance(y, cudf.Series) else y\n",
    "    \n",
    "    # Calculate class distributions\n",
    "    class_counts = np.bincount(y_cpu)\n",
    "    if verbose:\n",
    "        print(\"Original class distribution:\")\n",
    "        print(class_counts)\n",
    "    \n",
    "    # Define sampling strategy\n",
    "    sampling_strategy = {\n",
    "        1: int(class_counts[1] * 1.05),  \n",
    "        2: int(class_counts[2] * 1.2),   \n",
    "        3: int(class_counts[3] * 2.0),   \n",
    "        4: int(class_counts[4] * 3.0)    \n",
    "    }\n",
    "    \n",
    "    # Apply SMOTE with adaptive strategy\n",
    "    smote = SMOTE(\n",
    "        sampling_strategy=sampling_strategy,\n",
    "        random_state=42,\n",
    "        k_neighbors=min(5, min(class_counts[class_counts > 0]) - 1)\n",
    "    )\n",
    "    \n",
    "    # Combine SMOTE with RandomUnderSampler\n",
    "    under_sampler = RandomUnderSampler(sampling_strategy={0: int(class_counts[0] * 0.8)})\n",
    "    pipeline = make_pipeline(smote, under_sampler)\n",
    "    \n",
    "    X_resampled, y_resampled = pipeline.fit_resample(X_cpu, y_cpu)\n",
    "    \n",
    "    if verbose:\n",
    "        print(\"\\nClass distribution after sampling:\")\n",
    "        print(np.bincount(y_resampled))\n",
    "    \n",
    "    return X_resampled, y_resampled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 4: Define Model Evaluation Function\n",
    "def evaluate_model(model, X, y, dataset_name=\"\"):\n",
    "    print(f\"\\nEvaluating on {dataset_name}...\")\n",
    "    y_pred = model.predict(X)\n",
    "    \n",
    "    # Convert to correct types\n",
    "    y = y.astype('int32')\n",
    "    y_pred = cudf.Series(y_pred).astype('int32')\n",
    "    \n",
    "    # Calculate metrics\n",
    "    accuracy = accuracy_score(y, y_pred)\n",
    "    conf_mat = confusion_matrix(y, y_pred)\n",
    "    \n",
    "    # Calculate class-specific metrics\n",
    "    y_cpu = y.to_pandas()\n",
    "    y_pred_cpu = y_pred.to_pandas()\n",
    "    class_report = classification_report(y_cpu, y_pred_cpu, zero_division=0)\n",
    "    \n",
    "    print(f\"Accuracy: {accuracy:.3f}\")\n",
    "    print(\"\\nConfusion Matrix:\")\n",
    "    print(conf_mat)\n",
    "    print(\"\\nClassification Report:\")\n",
    "    print(class_report)\n",
    "    \n",
    "    # Print prediction distribution\n",
    "    print(\"\\nPrediction distribution:\")\n",
    "    print(y_pred.value_counts().sort_index().to_pandas())\n",
    "    print(\"\\nTrue label distribution:\")\n",
    "    print(y.value_counts().sort_index().to_pandas())\n",
    "    \n",
    "    return {\n",
    "        'accuracy': accuracy,\n",
    "        'confusion_matrix': conf_mat,\n",
    "        'classification_report': class_report\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 5: Define Main Function\n",
    "def main():\n",
    "    # Load and preprocess data\n",
    "    print(\"Loading and preprocessing data...\")\n",
    "    X_train, X_external, y_train, y_external = load_and_preprocess_data(\n",
    "        processed_train_path, processed_test_path\n",
    "    )\n",
    "    \n",
    "    # Split training data\n",
    "    print(\"\\nSplitting training data...\")\n",
    "    X_train_split, X_val, y_train_split, y_val = train_test_split(\n",
    "        X_train, y_train, test_size=0.2, random_state=42\n",
    "    )\n",
    "    \n",
    "    # Feature selection\n",
    "    print(\"\\nPerforming feature selection...\")\n",
    "    selector = SelectKBest(f_classif, k=50)\n",
    "    X_train_selected = selector.fit_transform(X_train_split.to_pandas(), y_train_split.to_pandas())\n",
    "    X_val_selected = selector.transform(X_val.to_pandas())\n",
    "    X_external_selected = selector.transform(X_external.to_pandas())\n",
    "    \n",
    "    # Balance training data\n",
    "    print(\"\\nBalancing training data...\")\n",
    "    X_train_balanced, y_train_balanced = adaptive_sampling(X_train_selected, y_train_split.to_pandas(), verbose=True)\n",
    "    X_train_balanced = cudf.DataFrame(X_train_balanced)\n",
    "    y_train_balanced = cudf.Series(y_train_balanced)\n",
    "    \n",
    "    # Create and train final model with Bagging\n",
    "    print(\"\\nTraining final model...\")\n",
    "    base_model = XGBClassifier(\n",
    "        n_estimators=150,\n",
    "        learning_rate=0.01,\n",
    "        max_depth=6,\n",
    "        min_child_weight=5,\n",
    "        subsample=0.7,\n",
    "        colsample_bytree=0.7,\n",
    "        reg_alpha=0.5,\n",
    "        reg_lambda=2,\n",
    "        objective='multi:softmax',\n",
    "        num_class=5,\n",
    "        random_state=42,\n",
    "        tree_method='hist',\n",
    "        device='cuda'\n",
    "    )\n",
    "    \n",
    "    # Use Bagging to improve model performance\n",
    "    final_model = BaggingClassifier(\n",
    "        estimator=base_model,\n",
    "        n_estimators=10,\n",
    "        random_state=42,\n",
    "        n_jobs=-1\n",
    "    )\n",
    "    \n",
    "    # Train final model\n",
    "    final_model.fit(X_train_balanced.to_pandas(), y_train_balanced.to_pandas())\n",
    "    \n",
    "    # Evaluate model\n",
    "    val_metrics = evaluate_model(final_model, X_val_selected, y_val, \"validation set\")\n",
    "    external_metrics = evaluate_model(final_model, X_external_selected, y_external, \"external test set\")\n",
    "    \n",
    "    return final_model, val_metrics, external_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading and preprocessing data...\n",
      "Loading and preprocessing data...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class distribution in training data:\n",
      "0    67343\n",
      "1    45927\n",
      "2    11656\n",
      "3      995\n",
      "4       52\n",
      "Name: multiclass_label, dtype: int64\n",
      "\n",
      "Splitting training data...\n",
      "\n",
      "Performing feature selection...\n",
      "\n",
      "Balancing training data...\n",
      "Original class distribution:\n",
      "[53844 36806  9290   797    42]\n",
      "\n",
      "Class distribution after sampling:\n",
      "[43075 38646 11148  1594   126]\n",
      "\n",
      "Training final model...\n",
      "\n",
      "Evaluating on validation set...\n",
      "Accuracy: 0.994\n",
      "\n",
      "Confusion Matrix:\n",
      "[[13452    12    19    16     0]\n",
      " [   11  9110     0     0     0]\n",
      " [   60     6  2300     0     0]\n",
      " [    9     0     0   189     0]\n",
      " [    7     0     0     0     3]]\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      1.00     13499\n",
      "           1       1.00      1.00      1.00      9121\n",
      "           2       0.99      0.97      0.98      2366\n",
      "           3       0.92      0.95      0.94       198\n",
      "           4       1.00      0.30      0.46        10\n",
      "\n",
      "    accuracy                           0.99     25194\n",
      "   macro avg       0.98      0.84      0.87     25194\n",
      "weighted avg       0.99      0.99      0.99     25194\n",
      "\n",
      "\n",
      "Prediction distribution:\n",
      "0    13539\n",
      "1     9128\n",
      "2     2319\n",
      "3      205\n",
      "4        3\n",
      "dtype: int64\n",
      "\n",
      "True label distribution:\n",
      "0    13499\n",
      "1     9121\n",
      "2     2366\n",
      "3      198\n",
      "4       10\n",
      "Name: multiclass_label, dtype: int64\n",
      "\n",
      "Evaluating on external test set...\n",
      "Accuracy: 0.811\n",
      "\n",
      "Confusion Matrix:\n",
      "[[10973   510   644     4     0]\n",
      " [  362  5363    16     0     0]\n",
      " [  413   204  1804     0     0]\n",
      " [ 2053     9     4   133     0]\n",
      " [   52     0     0     0     0]]\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.90      0.84     12131\n",
      "           1       0.88      0.93      0.91      5741\n",
      "           2       0.73      0.75      0.74      2421\n",
      "           3       0.97      0.06      0.11      2199\n",
      "           4       0.00      0.00      0.00        52\n",
      "\n",
      "    accuracy                           0.81     22544\n",
      "   macro avg       0.68      0.53      0.52     22544\n",
      "weighted avg       0.82      0.81      0.78     22544\n",
      "\n",
      "\n",
      "Prediction distribution:\n",
      "0    13853\n",
      "1     6086\n",
      "2     2468\n",
      "3      137\n",
      "dtype: int64\n",
      "\n",
      "True label distribution:\n",
      "0    12131\n",
      "1     5741\n",
      "2     2421\n",
      "3     2199\n",
      "4       52\n",
      "Name: multiclass_label, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Cell 6: Execute Main Function\n",
    "if __name__ == \"__main__\":\n",
    "    final_model, val_metrics, external_metrics = main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sl-nsl-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

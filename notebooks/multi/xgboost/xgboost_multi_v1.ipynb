{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 1: Import Libraries and Setup Paths\n",
    "import cudf\n",
    "import numpy as np\n",
    "from cuml.model_selection import train_test_split\n",
    "from xgboost import XGBClassifier\n",
    "from cuml.metrics import accuracy_score, confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Define paths\n",
    "processed_train_path = '/root/autodl-tmp/projects/SL_NSL/dataset/processed/multi/KDDTrain_processed.csv'\n",
    "processed_test_path = '/root/autodl-tmp/projects/SL_NSL/dataset/processed/multi/KDDTest_processed.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading processed training data...\n",
      "\n",
      "Checking for missing values in training data:\n",
      "dst_host_srv_count    0\n",
      "logged_in             0\n",
      "flag_SF               0\n",
      "service_http          0\n",
      "service_private       0\n",
      "                     ..\n",
      "urgent                0\n",
      "land                  0\n",
      "is_host_login         0\n",
      "service_tim_i         0\n",
      "multiclass_label      0\n",
      "Length: 110, dtype: int64\n",
      "\n",
      "Feature matrix shape: (125973, 109)\n",
      "Label distribution:\n",
      "0    67343\n",
      "1    45927\n",
      "2    11656\n",
      "3      995\n",
      "4       52\n",
      "Name: multiclass_label, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Cell 2: Load and Preprocess Training Data\n",
    "print(\"Loading processed training data...\")\n",
    "df_train = cudf.read_csv(processed_train_path)\n",
    "\n",
    "# Handle missing values in training data\n",
    "print(\"\\nChecking for missing values in training data:\")\n",
    "print(df_train.isnull().sum().to_pandas())\n",
    "\n",
    "# Fill missing values if any exist\n",
    "df_train = df_train.fillna(df_train.mean())\n",
    "\n",
    "# Select features and labels\n",
    "X = df_train.drop(columns=['multiclass_label']).astype('float32')\n",
    "y_multi = df_train['multiclass_label']\n",
    "\n",
    "# Display data info\n",
    "print(\"\\nFeature matrix shape:\", X.shape)\n",
    "print(\"Label distribution:\")\n",
    "print(y_multi.value_counts().to_pandas())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Splitting dataset into training and validation sets...\n",
      "Dataset split complete\n",
      "Training samples: 100779\n",
      "Validation samples: 25194\n"
     ]
    }
   ],
   "source": [
    "# Cell 3: Split Dataset into Training and Validation Sets\n",
    "print(\"\\nSplitting dataset into training and validation sets...\")\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y_multi, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "print(\"Dataset split complete\")\n",
    "print(f\"Training samples: {X_train.shape[0]}\")\n",
    "print(f\"Validation samples: {X_test.shape[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training XGBoost model...\n",
      "\n",
      "Top 10 most important features:\n",
      "                     feature  importance\n",
      "8              service_eco_i    0.271069\n",
      "21             service_ecr_i    0.203579\n",
      "12             diff_srv_rate    0.111916\n",
      "3               service_http    0.078523\n",
      "7   dst_host_srv_serror_rate    0.072739\n",
      "90                 src_bytes    0.060145\n",
      "28            wrong_fragment    0.054443\n",
      "6                      count    0.020290\n",
      "5     dst_host_diff_srv_rate    0.015705\n",
      "22                       hot    0.014073\n"
     ]
    }
   ],
   "source": [
    "# Cell 4: Train XGBoost Model and Analyze Feature Importance\n",
    "print(\"\\nTraining XGBoost model...\")\n",
    "xgb_multi = XGBClassifier(\n",
    "    n_estimators=100, \n",
    "    random_state=42,\n",
    "    tree_method='hist',\n",
    "    device='cuda',\n",
    "    objective='multi:softmax',  # Use softmax for multi-class classification\n",
    "    num_class=5  # Number of classes in the target variable\n",
    ")\n",
    "xgb_multi.fit(X_train, y_train)\n",
    "\n",
    "# Display feature importance\n",
    "feature_importance = cudf.DataFrame({\n",
    "    'feature': X.columns,\n",
    "    'importance': xgb_multi.feature_importances_\n",
    "})\n",
    "print(\"\\nTop 10 most important features:\")\n",
    "feature_importance = feature_importance.sort_values('importance', ascending=False).head(10)\n",
    "print(feature_importance.to_pandas())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluating on validation set...\n",
      "Validation Accuracy: 1.00\n",
      "\n",
      "Confusion Matrix:\n",
      "[[13490     0     4     0     4]\n",
      " [    2     0  9119     0     0]\n",
      " [    3     0     1     0  2362]\n",
      " [    3     0     0     0     0]\n",
      " [    1     0     0     0     1]]\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     13499\n",
      "           1       1.00      1.00      1.00      9121\n",
      "           2       1.00      1.00      1.00      2366\n",
      "           3       0.99      0.98      0.99       198\n",
      "           4       0.88      0.70      0.78        10\n",
      "\n",
      "    accuracy                           1.00     25194\n",
      "   macro avg       0.97      0.94      0.95     25194\n",
      "weighted avg       1.00      1.00      1.00     25194\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Cell 5: Evaluate Model on Validation Set\n",
    "print(\"\\nEvaluating on validation set...\")\n",
    "y_pred = xgb_multi.predict(X_test)\n",
    "\n",
    "# Convert to numpy arrays for sklearn metrics\n",
    "y_test_np = y_test.to_numpy()\n",
    "y_pred_np = y_pred if isinstance(y_pred, np.ndarray) else y_pred.to_numpy()\n",
    "\n",
    "# Calculate metrics\n",
    "accuracy = accuracy_score(y_test_np, y_pred_np)\n",
    "conf_matrix = confusion_matrix(y_test_np, y_pred_np)\n",
    "class_report = classification_report(y_test_np, y_pred_np)\n",
    "\n",
    "print(f\"Validation Accuracy: {accuracy:.2f}\")\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "print(conf_matrix)\n",
    "print(\"\\nClassification Report:\")\n",
    "print(class_report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluating on external test set...\n",
      "\n",
      "Checking for missing values in test data:\n",
      "dst_host_srv_count       0\n",
      "logged_in                0\n",
      "flag_SF                  0\n",
      "service_http             0\n",
      "service_private          0\n",
      "                      ... \n",
      "urgent                   0\n",
      "land                     0\n",
      "is_host_login            0\n",
      "service_tim_i            0\n",
      "multiclass_label      2420\n",
      "Length: 110, dtype: int64\n",
      "\n",
      "External Test Set Accuracy: 0.65\n",
      "\n",
      "Confusion Matrix:\n",
      "[[8064 2351 1710    0    6]\n",
      " [ 195 4852  694    0    0]\n",
      " [ 294  487 1635    5    0]\n",
      " [ 837  886  329  145    2]\n",
      " [  19   18    7    3    5]]\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.66      0.75     12131\n",
      "           1       0.56      0.85      0.68      5741\n",
      "           2       0.37      0.68      0.48      2421\n",
      "           3       0.95      0.07      0.12      2199\n",
      "           4       0.38      0.10      0.15        52\n",
      "\n",
      "    accuracy                           0.65     22544\n",
      "   macro avg       0.63      0.47      0.44     22544\n",
      "weighted avg       0.74      0.65      0.64     22544\n",
      "\n",
      "\n",
      "Prediction distribution:\n",
      "0    9409\n",
      "1    8594\n",
      "2    4375\n",
      "3     153\n",
      "4      13\n",
      "dtype: int64\n",
      "\n",
      "True label distribution:\n",
      "0    12131\n",
      "1     5741\n",
      "2     2421\n",
      "3     2199\n",
      "4       52\n",
      "Name: multiclass_label, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Cell 6: Evaluate Model on External Test Set\n",
    "print(\"\\nEvaluating on external test set...\")\n",
    "df_test = cudf.read_csv(processed_test_path)\n",
    "\n",
    "# Check for missing values in test data\n",
    "print(\"\\nChecking for missing values in test data:\")\n",
    "print(df_test.isnull().sum().to_pandas())\n",
    "\n",
    "# Fill missing values in test data\n",
    "df_test = df_test.fillna(df_test.mean())\n",
    "\n",
    "X_external_test = df_test.drop(columns=['multiclass_label']).astype('float32')\n",
    "y_external_test = df_test['multiclass_label'].astype('int32')\n",
    "\n",
    "# Make predictions\n",
    "y_external_pred = xgb_multi.predict(X_external_test)\n",
    "\n",
    "# Convert to numpy arrays for sklearn metrics\n",
    "y_external_test_np = y_external_test.to_numpy()\n",
    "y_external_pred_np = y_external_pred if isinstance(y_external_pred, np.ndarray) else y_external_pred.to_numpy()\n",
    "\n",
    "# Calculate metrics\n",
    "accuracy_external = accuracy_score(y_external_test_np, y_external_pred_np)\n",
    "conf_matrix_external = confusion_matrix(y_external_test_np, y_external_pred_np)\n",
    "class_report_external = classification_report(y_external_test_np, y_external_pred_np, zero_division=0)\n",
    "\n",
    "print(f\"\\nExternal Test Set Accuracy: {accuracy_external:.2f}\")\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "print(conf_matrix_external)\n",
    "print(\"\\nClassification Report:\")\n",
    "print(class_report_external)\n",
    "\n",
    "# Print the distribution of predicted labels\n",
    "print(\"\\nPrediction distribution:\")\n",
    "print(cudf.Series(y_external_pred).value_counts().sort_index().to_pandas())\n",
    "print(\"\\nTrue label distribution:\")\n",
    "print(cudf.Series(y_external_test).value_counts().sort_index().to_pandas())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sl-nsl-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

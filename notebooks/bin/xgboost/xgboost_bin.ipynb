{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 1: Import Libraries and Setup Paths\n",
    "import cudf\n",
    "import numpy as np\n",
    "from cuml.model_selection import train_test_split\n",
    "from xgboost import XGBClassifier\n",
    "from cuml.metrics import accuracy_score, confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Define paths\n",
    "processed_train_path = '/root/autodl-tmp/projects/SL_NSL/dataset/processed/KDDTrain_processed.csv'\n",
    "processed_test_path = '/root/autodl-tmp/projects/SL_NSL/dataset/processed/KDDTest_processed.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading processed training data...\n",
      "Feature matrix shape: (125973, 108)\n",
      "Label distribution:\n",
      "0    67343\n",
      "1    58630\n",
      "Name: binary_label, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Cell 2: Load and Preprocess Training Data\n",
    "# Load training data\n",
    "print(\"Loading processed training data...\")\n",
    "df_train = cudf.read_csv(processed_train_path)\n",
    "\n",
    "# Select features and labels\n",
    "X = df_train.drop(columns=['label', 'binary_label'])\n",
    "y_binary = df_train['binary_label']\n",
    "\n",
    "# Display data info\n",
    "print(\"Feature matrix shape:\", X.shape)\n",
    "print(\"Label distribution:\")\n",
    "print(y_binary.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset split complete\n",
      "Training samples: 100779\n",
      "Validation samples: 25194\n"
     ]
    }
   ],
   "source": [
    "# Cell 3: Split Dataset into Training and Validation Sets\n",
    "# Split into training and validation sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y_binary, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "print(\"Dataset split complete\")\n",
    "print(f\"Training samples: {X_train.shape[0]}\")\n",
    "print(f\"Validation samples: {X_test.shape[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training XGBoost model...\n",
      "\n",
      "Top 10 most important features:\n",
      "              feature  importance\n",
      "16      service_ecr_i    0.374037\n",
      "96          src_bytes    0.195503\n",
      "5        service_http    0.125345\n",
      "13      diff_srv_rate    0.056305\n",
      "2           logged_in    0.032049\n",
      "19     wrong_fragment    0.031102\n",
      "21   service_ftp_data    0.020335\n",
      "6     service_private    0.015249\n",
      "101         dst_bytes    0.014588\n",
      "71     is_guest_login    0.012392\n"
     ]
    }
   ],
   "source": [
    "# Cell 4: Train Model and Analyze Feature Importance\n",
    "# Create and train XGBoost model with GPU acceleration\n",
    "print(\"\\nTraining XGBoost model...\")\n",
    "xgb_binary = XGBClassifier(\n",
    "    n_estimators=50, \n",
    "    random_state=42,\n",
    "    tree_method='hist',\n",
    "    device='cuda'\n",
    ")\n",
    "xgb_binary.fit(X_train, y_train)\n",
    "\n",
    "# Display feature importance\n",
    "feature_importance = cudf.DataFrame({\n",
    "    'feature': X.columns,\n",
    "    'importance': xgb_binary.feature_importances_\n",
    "})\n",
    "print(\"\\nTop 10 most important features:\")\n",
    "feature_importance = feature_importance.sort_values('importance', ascending=False).head(10)\n",
    "print(feature_importance.to_pandas())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluating on validation set...\n",
      "Validation Accuracy: 1.00\n",
      "\n",
      "Confusion Matrix:\n",
      "[[13482    17]\n",
      " [   15 11680]]\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     13499\n",
      "           1       1.00      1.00      1.00     11695\n",
      "\n",
      "    accuracy                           1.00     25194\n",
      "   macro avg       1.00      1.00      1.00     25194\n",
      "weighted avg       1.00      1.00      1.00     25194\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Cell 5: Evaluate Model on Validation Set\n",
    "# Predict and evaluate on validation set\n",
    "print(\"\\nEvaluating on validation set...\")\n",
    "y_pred = xgb_binary.predict(X_test)\n",
    "\n",
    "# Convert to numpy arrays for sklearn metrics\n",
    "y_test_np = y_test.to_numpy()\n",
    "y_pred_np = y_pred if isinstance(y_pred, np.ndarray) else y_pred.to_numpy()\n",
    "\n",
    "# Calculate metrics\n",
    "accuracy = accuracy_score(y_test_np, y_pred_np)\n",
    "conf_matrix = confusion_matrix(y_test_np, y_pred_np)\n",
    "class_report = classification_report(y_test_np, y_pred_np)\n",
    "\n",
    "print(f\"Validation Accuracy: {accuracy:.2f}\")\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "print(conf_matrix)\n",
    "print(\"\\nClassification Report:\")\n",
    "print(class_report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluating on external test set...\n",
      "External Test Set Accuracy: 0.88\n",
      "\n",
      "Confusion Matrix:\n",
      "[[ 7257  2454]\n",
      " [  144 12689]]\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.75      0.85      9711\n",
      "           1       0.84      0.99      0.91     12833\n",
      "\n",
      "    accuracy                           0.88     22544\n",
      "   macro avg       0.91      0.87      0.88     22544\n",
      "weighted avg       0.90      0.88      0.88     22544\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Cell 6: Evaluate Model on External Test Set\n",
    "# Load and evaluate on external test set\n",
    "print(\"\\nEvaluating on external test set...\")\n",
    "df_test = cudf.read_csv(processed_test_path)\n",
    "\n",
    "X_external_test = df_test.drop(columns=['label', 'binary_label'])\n",
    "y_external_test = df_test['binary_label']\n",
    "\n",
    "# Make predictions\n",
    "y_external_pred = xgb_binary.predict(X_external_test)\n",
    "\n",
    "# Convert to numpy arrays for sklearn metrics\n",
    "y_external_test_np = y_external_test.to_numpy()\n",
    "y_external_pred_np = y_external_pred if isinstance(y_external_pred, np.ndarray) else y_external_pred.to_numpy()\n",
    "\n",
    "# Calculate metrics\n",
    "accuracy_external = accuracy_score(y_external_test_np, y_external_pred_np)\n",
    "conf_matrix_external = confusion_matrix(y_external_test_np, y_external_pred_np)\n",
    "class_report_external = classification_report(y_external_test_np, y_external_pred_np)\n",
    "\n",
    "print(f\"External Test Set Accuracy: {accuracy_external:.2f}\")\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "print(conf_matrix_external)\n",
    "print(\"\\nClassification Report:\")\n",
    "print(class_report_external)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rf-nsl-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 1: Imports and Path Definition\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import cudf\n",
    "import cupy as cp\n",
    "from sklearn.model_selection import train_test_split\n",
    "from cuml import RandomForestClassifier as cuRF\n",
    "from xgboost import XGBClassifier\n",
    "from cuml.metrics import accuracy_score\n",
    "from cuml.metrics.confusion_matrix import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Define paths\n",
    "processed_train_path = '/root/autodl-tmp/projects/SL_NSL/dataset/processed/bin/KDDTrain_processed.csv'\n",
    "processed_test_path = '/root/autodl-tmp/projects/SL_NSL/dataset/processed/bin/KDDTest_processed.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading processed training data...\n",
      "Feature matrix shape: (125973, 108)\n",
      "Label distribution:\n",
      "0    67343\n",
      "1    58630\n",
      "Name: binary_label, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Cell 2: Load and Prepare Training Data\n",
    "print(\"Loading processed training data...\")\n",
    "df_train = cudf.read_csv(processed_train_path)\n",
    "\n",
    "# Select features and labels and convert to appropriate types\n",
    "X = df_train.drop(columns=['binary_label']).astype('float32')\n",
    "y_binary = df_train['binary_label'].astype('int32')\n",
    "\n",
    "# Display data info\n",
    "print(\"Feature matrix shape:\", X.shape)\n",
    "print(\"Label distribution:\")\n",
    "print(y_binary.value_counts().to_pandas())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset split complete\n",
      "Training samples: 100778\n",
      "Validation samples: 25195\n"
     ]
    }
   ],
   "source": [
    "# Cell 3: Train-Test Split\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y_binary, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "# Convert data types\n",
    "X_train = X_train.astype('float32')\n",
    "X_test = X_test.astype('float32')\n",
    "y_train = y_train.astype('int32')\n",
    "y_test = y_test.astype('int32')\n",
    "\n",
    "print(\"Dataset split complete\")\n",
    "print(f\"Training samples: {X_train.shape[0]}\")\n",
    "print(f\"Validation samples: {X_test.shape[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training Random Forest model on GPU...\n",
      "\n",
      "Training XGBoost model on GPU...\n",
      "\n",
      "Top 10 most important features (XGBoost):\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>flag_SF</td>\n",
       "      <td>0.209945</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>src_bytes</td>\n",
       "      <td>0.164143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>service_ecr_i</td>\n",
       "      <td>0.141934</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>protocol_type_icmp</td>\n",
       "      <td>0.092086</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>service_http</td>\n",
       "      <td>0.058661</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101</th>\n",
       "      <td>dst_bytes</td>\n",
       "      <td>0.052461</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>diff_srv_rate</td>\n",
       "      <td>0.029770</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>service_private</td>\n",
       "      <td>0.022431</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>count</td>\n",
       "      <td>0.022201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>logged_in</td>\n",
       "      <td>0.016933</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                feature  importance\n",
       "0               flag_SF    0.209945\n",
       "96            src_bytes    0.164143\n",
       "16        service_ecr_i    0.141934\n",
       "14   protocol_type_icmp    0.092086\n",
       "5          service_http    0.058661\n",
       "101           dst_bytes    0.052461\n",
       "13        diff_srv_rate    0.029770\n",
       "6       service_private    0.022431\n",
       "4                 count    0.022201\n",
       "2             logged_in    0.016933"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Cell 4: Model Training and Feature Importance Analysis\n",
    "# Create and train Random Forest model (GPU)\n",
    "print(\"\\nTraining Random Forest model on GPU...\")\n",
    "rf_model = cuRF(\n",
    "    n_estimators=50,\n",
    "    random_state=42,\n",
    "    n_streams=1\n",
    ")\n",
    "rf_model.fit(X_train, y_train)\n",
    "\n",
    "# Create and train XGBoost model (GPU)\n",
    "print(\"\\nTraining XGBoost model on GPU...\")\n",
    "xgb_model = XGBClassifier(\n",
    "    n_estimators=50,\n",
    "    random_state=42,\n",
    "    tree_method='hist',\n",
    "    device='cuda:0',\n",
    "    max_depth=8,\n",
    "    learning_rate=0.1,\n",
    "    min_child_weight=1,\n",
    "    subsample=0.8,\n",
    "    colsample_bytree=0.8,\n",
    "    eval_metric='logloss'\n",
    ")\n",
    "\n",
    "# Train XGBoost model\n",
    "xgb_model.fit(X_train.to_pandas(), y_train.to_pandas(), verbose=True)\n",
    "\n",
    "# Get XGBoost feature importance\n",
    "print(\"\\nTop 10 most important features (XGBoost):\")\n",
    "feature_importance = pd.DataFrame({\n",
    "    'feature': X.columns.values,\n",
    "    'importance': xgb_model.feature_importances_\n",
    "})\n",
    "display(feature_importance.sort_values('importance', ascending=False).head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluating ensemble on validation set...\n",
      "Validation Accuracy: 1.00\n",
      "\n",
      "Confusion Matrix:\n",
      "[[13409    13]\n",
      " [   29 11744]]\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     13422\n",
      "           1       1.00      1.00      1.00     11773\n",
      "\n",
      "    accuracy                           1.00     25195\n",
      "   macro avg       1.00      1.00      1.00     25195\n",
      "weighted avg       1.00      1.00      1.00     25195\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Cell 5: Validation Set Evaluation\n",
    "def get_ensemble_predictions(X_data, rf_weight=0.4, xgb_weight=0.6):\n",
    "    \"\"\"\n",
    "    Get weighted ensemble predictions from RF and XGBoost models\n",
    "    \"\"\"\n",
    "    # Convert X_data to appropriate formats for each model\n",
    "    X_data_gpu = X_data.astype('float32') if isinstance(X_data, cudf.DataFrame) else cudf.DataFrame(X_data).astype('float32')\n",
    "    X_data_cpu = X_data.to_pandas() if isinstance(X_data, cudf.DataFrame) else X_data\n",
    "    \n",
    "    # Get probability predictions from both models\n",
    "    rf_probs = rf_model.predict_proba(X_data_gpu)\n",
    "    xgb_probs = xgb_model.predict_proba(X_data_cpu)\n",
    "    \n",
    "    # Convert predictions to numpy arrays\n",
    "    rf_probs = cp.asnumpy(rf_probs) if isinstance(rf_probs, cp.ndarray) else rf_probs.to_numpy()\n",
    "    xgb_probs = np.array(xgb_probs)\n",
    "    \n",
    "    # Weighted average of probabilities\n",
    "    ensemble_probs = rf_probs * rf_weight + xgb_probs * xgb_weight\n",
    "    \n",
    "    # Convert to class predictions\n",
    "    return np.argmax(ensemble_probs, axis=1)\n",
    "\n",
    "# Evaluate on validation set\n",
    "print(\"\\nEvaluating ensemble on validation set...\")\n",
    "y_pred = get_ensemble_predictions(X_test)\n",
    "y_pred = cudf.Series(y_pred).astype('int32')\n",
    "\n",
    "# Calculate metrics\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "# Convert to CPU for classification report\n",
    "y_test_cpu = y_test.to_pandas()\n",
    "y_pred_cpu = y_pred.to_pandas()\n",
    "class_report = classification_report(y_test_cpu, y_pred_cpu)\n",
    "\n",
    "print(f\"Validation Accuracy: {accuracy:.2f}\")\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "print(conf_matrix)\n",
    "print(\"\\nClassification Report:\")\n",
    "print(class_report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluating ensemble on external test set...\n",
      "External Test Set Accuracy: 0.86\n",
      "\n",
      "Confusion Matrix:\n",
      "[[ 7091  2620]\n",
      " [  527 12306]]\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.73      0.82      9711\n",
      "           1       0.82      0.96      0.89     12833\n",
      "\n",
      "    accuracy                           0.86     22544\n",
      "   macro avg       0.88      0.84      0.85     22544\n",
      "weighted avg       0.87      0.86      0.86     22544\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Cell 6: External Test Set Evaluation\n",
    "print(\"\\nEvaluating ensemble on external test set...\")\n",
    "df_test = cudf.read_csv(processed_test_path)\n",
    "\n",
    "X_external_test = df_test.drop(columns=['binary_label']).astype('float32')\n",
    "y_external_test = df_test['binary_label'].astype('int32')\n",
    "\n",
    "# Make predictions\n",
    "y_external_pred = get_ensemble_predictions(X_external_test)\n",
    "y_external_pred = cudf.Series(y_external_pred).astype('int32')\n",
    "\n",
    "# Calculate metrics\n",
    "accuracy_external = accuracy_score(y_external_test, y_external_pred)\n",
    "conf_matrix_external = confusion_matrix(y_external_test, y_external_pred)\n",
    "\n",
    "# Convert to CPU for classification report\n",
    "y_external_test_cpu = y_external_test.to_pandas()\n",
    "y_external_pred_cpu = y_external_pred.to_pandas()\n",
    "class_report_external = classification_report(y_external_test_cpu, y_external_pred_cpu)\n",
    "\n",
    "print(f\"External Test Set Accuracy: {accuracy_external:.2f}\")\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "print(conf_matrix_external)\n",
    "print(\"\\nClassification Report:\")\n",
    "print(class_report_external)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sl-nsl-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

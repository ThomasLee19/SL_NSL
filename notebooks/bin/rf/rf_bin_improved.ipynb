{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 1: Import Libraries and Setup Paths\n",
    "import cudf\n",
    "import cupy as cp\n",
    "import numpy as np\n",
    "from cuml.ensemble import RandomForestClassifier\n",
    "from cuml.model_selection import train_test_split\n",
    "from cuml.metrics import accuracy_score, confusion_matrix\n",
    "from sklearn.metrics import classification_report, make_scorer, f1_score\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from cuml.model_selection import GridSearchCV\n",
    "\n",
    "# Define paths\n",
    "processed_train_path = '/root/autodl-tmp/projects/SL_NSL/dataset/processed/KDDTrain_processed.csv'\n",
    "processed_test_path = '/root/autodl-tmp/projects/SL_NSL/dataset/processed/KDDTest_processed.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading processed training data...\n",
      "Training and test sets split completed\n",
      "Number of training samples: 100779\n",
      "Number of test samples: 25194\n",
      "Feature data type: float32\n",
      "Label data type: int32\n"
     ]
    }
   ],
   "source": [
    "# Cell 2: Load and Split Data\n",
    "print(\"Loading processed training data...\")\n",
    "df_train = cudf.read_csv(processed_train_path)\n",
    "\n",
    "# Define type conversion for feature columns\n",
    "feature_columns = [col for col in df_train.columns if col not in ['label', 'binary_label']]\n",
    "df_train[feature_columns] = df_train[feature_columns].astype('float32')\n",
    "\n",
    "# Select features and labels\n",
    "X = df_train.drop(columns=['label', 'binary_label'])\n",
    "y_binary = df_train['binary_label'].astype('int32')\n",
    "\n",
    "# Split the dataset into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y_binary, test_size=0.2, random_state=42)\n",
    "\n",
    "print(\"Training and test sets split completed\")\n",
    "print(f\"Number of training samples: {X_train.shape[0]}\")\n",
    "print(f\"Number of test samples: {X_test.shape[0]}\")\n",
    "print(f\"Feature data type: {X_train.dtypes[0]}\")\n",
    "print(f\"Label data type: {y_train.dtype}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 3: Create Enhanced Random Forest Classifier\n",
    "rf_binary = RandomForestClassifier(\n",
    "    n_estimators=100,\n",
    "    max_depth=10,\n",
    "    min_samples_leaf=10,\n",
    "    min_samples_split=20,\n",
    "    max_features='sqrt',\n",
    "    n_bins=256,  # Added for GPU optimization\n",
    "    n_streams=1,     # Added for reproducibility\n",
    "    random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 4: Setup Sampling and Grid Search\n",
    "# Initialize samplers\n",
    "smote = SMOTE(random_state=42, sampling_strategy='auto')\n",
    "\n",
    "# Parameter grid for grid search\n",
    "param_grid = {\n",
    "    'n_estimators': [50, 100, 150, 200],\n",
    "    'max_depth': [8, 10, 12, 15, 20],\n",
    "    'min_samples_split': [15, 20, 25, 30],\n",
    "    'max_features': ['sqrt', 'auto', 0.3, 0.5, 0.7], \n",
    "    'min_samples_leaf': [5, 10, 15],\n",
    "    'n_bins': [128, 256]\n",
    "}\n",
    "\n",
    "# Create stratified K-fold cross validation\n",
    "cv = StratifiedKFold(n_splits=10, shuffle=True, random_state=42)\n",
    "\n",
    "# Custom scorer for GPU\n",
    "def gpu_f1_score(y_true, y_pred):\n",
    "    y_true_cpu = y_true.to_pandas() if isinstance(y_true, cudf.Series) else y_true\n",
    "    y_pred_cpu = y_pred.to_pandas() if isinstance(y_pred, cudf.Series) else y_pred\n",
    "    return f1_score(y_true_cpu, y_pred_cpu, average='weighted')\n",
    "\n",
    "scorer = make_scorer(gpu_f1_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 5: Create Grid Search\n",
    "grid_search = GridSearchCV(\n",
    "    estimator=rf_binary,\n",
    "    param_grid=param_grid,\n",
    "    cv=cv,\n",
    "    scoring=scorer,\n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 6: Training and Evaluation Function\n",
    "def train_and_evaluate(X_train, X_test, y_train, y_test, X_external=None, y_external=None):\n",
    "    # Convert data to CPU for sampling and ensure float32, labels as int32\n",
    "    X_train_cpu = X_train.to_numpy().astype('float32')\n",
    "    y_train_cpu = y_train.to_numpy().astype('int32')\n",
    "    \n",
    "    # Apply SMOTE to balance the dataset\n",
    "    print(\"Applying SMOTE to balance training data...\")\n",
    "    X_train_balanced, y_train_balanced = smote.fit_resample(X_train_cpu, y_train_cpu)\n",
    "    \n",
    "    # Convert back to GPU for training\n",
    "    X_train_gpu = cudf.DataFrame(X_train_balanced).astype('float32')\n",
    "    y_train_gpu = cudf.Series(y_train_balanced).astype('int32')\n",
    "    \n",
    "    # Train model directly without grid search first\n",
    "    print(\"Training initial model...\")\n",
    "    model = RandomForestClassifier(\n",
    "        n_estimators=100,\n",
    "        max_depth=10,\n",
    "        min_samples_leaf=10,\n",
    "        min_samples_split=20,\n",
    "        max_features='sqrt',\n",
    "        n_bins=128,\n",
    "        n_streams=1,\n",
    "        random_state=42\n",
    "    )\n",
    "    model.fit(X_train_gpu, y_train_gpu)\n",
    "    \n",
    "    # Manual grid search implementation\n",
    "    print(\"\\nPerforming manual grid search...\")\n",
    "    best_score = 0\n",
    "    best_params = {}\n",
    "    best_model = None\n",
    "    \n",
    "    for n_est in param_grid['n_estimators']:\n",
    "        for depth in param_grid['max_depth']:\n",
    "            for min_split in param_grid['min_samples_split']:\n",
    "                for max_feat in param_grid['max_features']:\n",
    "                    current_model = RandomForestClassifier(\n",
    "                        n_estimators=n_est,\n",
    "                        max_depth=depth,\n",
    "                        min_samples_split=min_split,\n",
    "                        max_features=max_feat,\n",
    "                        min_samples_leaf=10,\n",
    "                        n_bins=128,\n",
    "                        n_streams=1,\n",
    "                        random_state=42\n",
    "                    )\n",
    "                    \n",
    "                    # Train and evaluate\n",
    "                    current_model.fit(X_train_gpu, y_train_gpu)\n",
    "                    y_pred = current_model.predict(X_test)\n",
    "                    score = gpu_f1_score(y_test, y_pred)\n",
    "                    \n",
    "                    if score > best_score:\n",
    "                        best_score = score\n",
    "                        best_params = {\n",
    "                            'n_estimators': n_est,\n",
    "                            'max_depth': depth,\n",
    "                            'min_samples_split': min_split,\n",
    "                            'max_features': max_feat\n",
    "                        }\n",
    "                        best_model = current_model\n",
    "                        print(f\"New best score: {best_score:.3f} with params: {best_params}\")\n",
    "    \n",
    "    print(\"\\nBest parameters:\", best_params)\n",
    "    \n",
    "    # Evaluate on internal test set\n",
    "    print(\"\\nInternal Test Set Evaluation:\")\n",
    "    y_pred = best_model.predict(X_test)\n",
    "\n",
    "    # Ensure all labels are int32 for metrics calculation\n",
    "    y_test_int = y_test.astype('int32')\n",
    "    y_pred_int = y_pred.astype('int32')\n",
    "    \n",
    "    # Calculate metrics\n",
    "    internal_metrics = {\n",
    "        'accuracy': accuracy_score(y_test_int, y_pred_int),\n",
    "        'confusion_matrix': confusion_matrix(y_test_int, y_pred_int),\n",
    "        'classification_report': classification_report(\n",
    "            y_test_int.to_numpy(), \n",
    "            y_pred_int.to_numpy()\n",
    "        )\n",
    "    }\n",
    "    \n",
    "    # Print internal evaluation results\n",
    "    print(f\"Accuracy: {internal_metrics['accuracy']:.3f}\")\n",
    "    print(\"\\nConfusion Matrix:\")\n",
    "    print(internal_metrics['confusion_matrix'])\n",
    "    print(\"\\nClassification Report:\")\n",
    "    print(internal_metrics['classification_report'])\n",
    "    \n",
    "    # Calculate cross-validation scores\n",
    "    print(\"\\nPerforming cross-validation...\")\n",
    "    cv_scores = []\n",
    "    for train_idx, val_idx in cv.split(X_train_gpu.to_numpy(), y_train_gpu.to_numpy()):\n",
    "        # Convert indices to GPU\n",
    "        X_fold_train = X_train_gpu.iloc[train_idx]\n",
    "        y_fold_train = y_train_gpu.iloc[train_idx]\n",
    "        X_fold_val = X_train_gpu.iloc[val_idx]\n",
    "        y_fold_val = y_train_gpu.iloc[val_idx]\n",
    "        \n",
    "        # Apply sampling to fold\n",
    "        X_fold_train_cpu = X_fold_train.to_numpy()\n",
    "        y_fold_train_cpu = y_fold_train.to_numpy()\n",
    "        X_fold_balanced, y_fold_balanced = smote.fit_resample(X_fold_train_cpu, y_fold_train_cpu)\n",
    "        \n",
    "        # Convert back to GPU\n",
    "        X_fold_train_gpu = cudf.DataFrame(X_fold_balanced)\n",
    "        y_fold_train_gpu = cudf.Series(y_fold_balanced)\n",
    "        \n",
    "        # Train and evaluate\n",
    "        fold_model = best_model.fit(X_fold_train_gpu, y_fold_train_gpu)\n",
    "        y_fold_pred = fold_model.predict(X_fold_val)\n",
    "        cv_scores.append(gpu_f1_score(y_fold_val, y_fold_pred))\n",
    "    \n",
    "    cv_scores = np.array(cv_scores)\n",
    "    print(f\"Cross-validation F1 scores: {cv_scores.mean():.3f} (+/- {cv_scores.std() * 2:.3f})\")\n",
    "    \n",
    "    # External evaluation   \n",
    "    if X_external is not None and y_external is not None:\n",
    "        print(\"\\nExternal Test Set Evaluation:\")\n",
    "        y_external_pred = best_model.predict(X_external)\n",
    "\n",
    "        y_external_int = y_external.astype('int32')\n",
    "        y_external_pred_int = y_external_pred.astype('int32')\n",
    "        \n",
    "        external_metrics = {\n",
    "            'accuracy': accuracy_score(y_external_int, y_external_pred_int),\n",
    "            'confusion_matrix': confusion_matrix(y_external_int, y_external_pred_int),\n",
    "            'classification_report': classification_report(\n",
    "                y_external_int.to_numpy(),\n",
    "                y_external_pred_int.to_numpy()\n",
    "            )\n",
    "        }\n",
    "        \n",
    "        print(f\"Accuracy: {external_metrics['accuracy']:.3f}\")\n",
    "        print(\"\\nConfusion Matrix:\")\n",
    "        print(external_metrics['confusion_matrix'])\n",
    "        print(\"\\nClassification Report:\")\n",
    "        print(external_metrics['classification_report'])\n",
    "        \n",
    "        return best_model, internal_metrics, external_metrics\n",
    "    \n",
    "    return best_model, internal_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 7: Early Stopping Monitor\n",
    "def monitor_training(model, X_val, y_val, patience=3):\n",
    "    \"\"\"Monitor training process and implement early stopping\"\"\"\n",
    "    best_score = 0\n",
    "    patience_counter = 0\n",
    "    \n",
    "    for i in range(model.n_estimators):\n",
    "        model.n_estimators = i + 1\n",
    "        model.fit(X_val, y_val)\n",
    "        \n",
    "        # Calculate score on GPU\n",
    "        y_pred = model.predict(X_val)\n",
    "        current_score = accuracy_score(y_val, y_pred)\n",
    "        \n",
    "        if current_score > best_score:\n",
    "            best_score = current_score\n",
    "            patience_counter = 0\n",
    "        else:\n",
    "            patience_counter += 1\n",
    "            \n",
    "        if patience_counter >= patience:\n",
    "            print(f\"Early stopping at iteration {i}\")\n",
    "            break\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Applying SMOTE to balance training data...\n",
      "Training initial model...\n",
      "\n",
      "Performing manual grid search...\n",
      "New best score: 0.986 with params: {'n_estimators': 50, 'max_depth': 8, 'min_samples_split': 15, 'max_features': 'sqrt'}\n",
      "New best score: 0.997 with params: {'n_estimators': 50, 'max_depth': 8, 'min_samples_split': 15, 'max_features': 0.3}\n",
      "New best score: 0.997 with params: {'n_estimators': 50, 'max_depth': 8, 'min_samples_split': 15, 'max_features': 0.7}\n",
      "New best score: 0.997 with params: {'n_estimators': 50, 'max_depth': 8, 'min_samples_split': 25, 'max_features': 0.3}\n",
      "New best score: 0.997 with params: {'n_estimators': 50, 'max_depth': 8, 'min_samples_split': 25, 'max_features': 0.7}\n",
      "New best score: 0.997 with params: {'n_estimators': 50, 'max_depth': 8, 'min_samples_split': 30, 'max_features': 0.3}\n",
      "New best score: 0.997 with params: {'n_estimators': 50, 'max_depth': 8, 'min_samples_split': 30, 'max_features': 0.5}\n",
      "New best score: 0.998 with params: {'n_estimators': 50, 'max_depth': 10, 'min_samples_split': 15, 'max_features': 0.3}\n",
      "New best score: 0.998 with params: {'n_estimators': 50, 'max_depth': 10, 'min_samples_split': 15, 'max_features': 0.5}\n",
      "New best score: 0.998 with params: {'n_estimators': 50, 'max_depth': 10, 'min_samples_split': 15, 'max_features': 0.7}\n",
      "New best score: 0.998 with params: {'n_estimators': 50, 'max_depth': 10, 'min_samples_split': 30, 'max_features': 0.5}\n",
      "New best score: 0.998 with params: {'n_estimators': 50, 'max_depth': 10, 'min_samples_split': 30, 'max_features': 0.7}\n",
      "New best score: 0.998 with params: {'n_estimators': 50, 'max_depth': 15, 'min_samples_split': 15, 'max_features': 0.3}\n",
      "New best score: 0.998 with params: {'n_estimators': 50, 'max_depth': 20, 'min_samples_split': 15, 'max_features': 0.3}\n",
      "New best score: 0.999 with params: {'n_estimators': 100, 'max_depth': 20, 'min_samples_split': 15, 'max_features': 0.5}\n",
      "\n",
      "Best parameters: {'n_estimators': 100, 'max_depth': 20, 'min_samples_split': 15, 'max_features': 0.5}\n",
      "\n",
      "Internal Test Set Evaluation:\n",
      "Accuracy: 0.999\n",
      "\n",
      "Confusion Matrix:\n",
      "[[13480    19]\n",
      " [   18 11677]]\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     13499\n",
      "           1       1.00      1.00      1.00     11695\n",
      "\n",
      "    accuracy                           1.00     25194\n",
      "   macro avg       1.00      1.00      1.00     25194\n",
      "weighted avg       1.00      1.00      1.00     25194\n",
      "\n",
      "\n",
      "Performing cross-validation...\n",
      "Cross-validation F1 scores: 0.998 (+/- 0.001)\n",
      "\n",
      "External Test Set Evaluation:\n",
      "Accuracy: 0.857\n",
      "\n",
      "Confusion Matrix:\n",
      "[[ 6740  2971]\n",
      " [  262 12571]]\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.69      0.81      9711\n",
      "           1       0.81      0.98      0.89     12833\n",
      "\n",
      "    accuracy                           0.86     22544\n",
      "   macro avg       0.89      0.84      0.85     22544\n",
      "weighted avg       0.88      0.86      0.85     22544\n",
      "\n",
      "\n",
      "Final Model Training Complete!\n",
      "Internal Test Accuracy: 0.999\n",
      "External Test Accuracy: 0.857\n"
     ]
    }
   ],
   "source": [
    "# Cell 8: Run Training and Evaluation\n",
    "# Load external test data\n",
    "df_test = cudf.read_csv(processed_test_path)\n",
    "\n",
    "# Convert numeric columns to float32\n",
    "numeric_columns = df_test.select_dtypes(include=['float64', 'int64']).columns\n",
    "df_test[numeric_columns] = df_test[numeric_columns].astype('float32')\n",
    "\n",
    "X_external = df_test.drop(columns=['label', 'binary_label']).astype('float32')\n",
    "y_external = df_test['binary_label'].astype('int32')\n",
    "\n",
    "# Run training and evaluation\n",
    "best_model, internal_metrics, external_metrics = train_and_evaluate(\n",
    "    X_train, X_test, y_train, y_test,\n",
    "    X_external=X_external,\n",
    "    y_external=y_external\n",
    ")\n",
    "\n",
    "# Print final results summary\n",
    "print(\"\\nFinal Model Training Complete!\")\n",
    "print(f\"Internal Test Accuracy: {internal_metrics['accuracy']:.3f}\")\n",
    "print(f\"External Test Accuracy: {external_metrics['accuracy']:.3f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rf-nsl-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
